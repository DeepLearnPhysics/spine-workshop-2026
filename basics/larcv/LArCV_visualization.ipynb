{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb08378e-7100-4663-8b79-53573a24b0d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LArCV Labeling\n",
    "\n",
    "The reconstruction chain operates on a specific type of data files: [LArCV](https://github.com/LArbys/LArCV) (Liquid Argon Computer Vision). These files are ROOT files with basic data representations relevant to doing machine learning (ML) in LArTPCs. They contain only the necessary information for ML-based reconstruction algorithms and can be loaded fast, so as to not restrict the execution speed.\n",
    "\n",
    "These files are produced from either:\n",
    "- `stage1` files (with SpacePoint data products) files in LArSoft (DUNE-FD and its prototypes)\n",
    "- `flow` files (with prompt hits data products) files in ndlar-flow (DUNE-ND and its prototypes)\n",
    "\n",
    "The follow up three tutorials (tomorrow) will show you how to produce these files. This tutorial will focus on the content of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9799e-2296-465f-913d-24a12c7811e7",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## I. Browsing a LArCV file using ROOT\n",
    "\n",
    "The basic container used in this workshop contains the necessary ROOT and LArCV dependencies. If you are running this locally, you will need to build LArCV2 (requires ROOT): [https://github.com/DeepLearnPhysics/larcv2](https://github.com/DeepLearnPhysics/larcv2)\n",
    "\n",
    "There are multiple ways to look at the content of a LArCV ROOT file:\n",
    "1. Use TBrowser\n",
    "```shell\n",
    "$ rootbrowse file.root\n",
    "```\n",
    "2. Load file in a ROOT interactive shell\n",
    "```shell\n",
    "$ root -l\n",
    "root [0] f = TFile(\"file.root\");\n",
    "root [1] f.ls()\n",
    "```\n",
    "3. Load file using PyROOT\n",
    "\n",
    "4. Load file using [uproot](https://uproot.readthedocs.io/en/latest/basic.html)\n",
    "\n",
    "Let's take a look at the contents of a `LArCV` simulation file using PyROOT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd08daf-e1e9-4c39-9663-b0d69684da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import larcv\n",
    "import ROOT\n",
    "\n",
    "fname = '/global/cfs/cdirs/m5252/dune/spine/workshop/larcv/protodune-vd_small.root' # Change this path if you are not on NERSC\n",
    "#fname = 'LOCAL_PATH'\n",
    "f = ROOT.TFile(fname)\n",
    "f.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c7acd-658f-4daa-a51e-8e1b809e3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "tree = uproot.open(fname)\n",
    "tree.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125082f3-5f3f-49a1-b700-812c137c9251",
   "metadata": {},
   "source": [
    "There are several data types, as you can see:\n",
    "- `sparse3d_*` refers to a [larcv::EventSparseTensor3D](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/EventVoxel3D.h#L47), a tensor of voxel coordinates\n",
    "  - Each `SparseTensor3D` is a list of `(voxel_id, value)` pairs which can map to a list of `(x, y, z, value)`\n",
    "  - E.g. charge per voxel, semantic label, cluster label, etc.\n",
    "- `cluster3d_*` refers to a [larcv::EventClusterVoxel3D](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/EventVoxel3D.h#L27), a list of tensor coordinates\n",
    "  - Each `ClusterVoxel3D` object contains a list of SparseTensor3D, typically one per particle\n",
    "- `particle_*` refers to a [larcv::EventParticle](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/EventParticle.h#L26), a list of [larcv::Particle](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/Particle.h#L27) objects\n",
    "  - Each `Particle` object has a bunch of MC truth particle level attributes\n",
    "  - E.g. start/end points, PDG code, creation process, etc.\n",
    "- `neutrino_*` refers to a [larcv::EventNeutrino](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/EventNeutrino.h#L26), a list of [larcv::Neutrino](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/Neutrino.h#L27) objects\n",
    "  - Each `Neutrino` object has a bunch  of MC truth neutrino level attributes\n",
    "  - E.g. vertex, interaction type (CC, NC), neutrino energy, etc.\n",
    "- `opflash_*` refers to a [larcv::Flash](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/Flash.h#L25)\n",
    "  - Dumps out the list of flash and their associated information\n",
    "  - E.g. PE sum in each PMT, flash time, etc.\n",
    "- `crthit_*` refers to a [larcv::CRTHit](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/CRTHit.h#L28)\n",
    "  - Dumps out the list of CRT hits and their associated information\n",
    "  - E.g. PE sum in the hit, hit time, location of the CRT plane, etc.\n",
    "- `trigger_*` refers to a [larcv::Trigger](https://github.com/DeepLearnPhysics/larcv2/blob/develop/larcv/core/DataFormat/Trigger.h)\n",
    "  - Contains trigger information (index, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78012dc-9a29-4d85-95d3-6ca0f2259f15",
   "metadata": {},
   "source": [
    "***\n",
    "### Check content\n",
    "\n",
    "There are ways to check on the content of the LArCV file, for instance one can dump the size of each cluster of points in each event (image), i.e. the size of each particle, following this procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d57e49-497f-45a3-ae8d-7c1a93cbd83e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tree = f.Get(\"cluster3d_pcluster_tree\")\n",
    "print('Number of entries', tree.GetEntries())\n",
    "\n",
    "for entry in range(tree.GetEntries()):\n",
    "    tree.GetEntry(entry)\n",
    "    event = tree.cluster3d_pcluster_branch\n",
    "    clusters = event.as_vector()\n",
    "    print(\"Number of clusters = \", len(clusters))\n",
    "    cluster_sizes = []\n",
    "    for c in clusters:\n",
    "        cluster_sizes.append(c.as_vector().size())\n",
    "    print(np.array(cluster_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841371c-6171-45eb-9e51-37a15f6d1f9d",
   "metadata": {},
   "source": [
    "Now close the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85234122-0260-427a-bdc8-9f1826b1e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c53fab-837b-4d3b-a742-79c045d86413",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## II. Browsing the LArCV file using `SPINE`\n",
    "\n",
    "Before starting anything, it is good practice to look at your dataset in an event display. This chapter is strictly about the I/O part of SPINE (independently of everything else, models, etc) and how to use it to visualize your dataset.\n",
    "\n",
    "Two options to gain access to SPINE (not pre-packaged in the image):\n",
    "- `pip install`\n",
    "- Point to a local install at NERSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906aa3f-2a98-4968-b2d1-7549b65b403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# Set software directory (alternative)\n",
    "# SOFTWARE_DIR = '/global/cfs/cdirs/m5252/software/spine/src/' # Change this path if you are not on NERSC. This can work instead of pip install\n",
    "# sys.path.insert(0, SOFTWARE_DIR)\n",
    "\n",
    "%pip install --user --upgrade spine-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f0697-ef33-4214-9df8-59562359bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c71f3e-0734-4e49-a731-76e0e576ea4e",
   "metadata": {},
   "source": [
    "Set up path to the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9420d0-8854-480a-8276-43b23cf58aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/global/cfs/cdirs/m5252/dune/spine/workshop/larcv/' # Change this path if you are not on NERSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b7b09-d170-4f35-b33f-0eb8ed51b3c9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "You need to specify a *configuration*, in YAML syntax, which tells `SPINE` how you want to access the data: how many images (`batch_size`), the path to your dataset, which quantities you want to retrieve from the dataset. You can even limit the I/O to a specific list of entry numbers using `entry_list`, or skip a list with `skip_entry_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3279a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTOR = 'protodune-vd'\n",
    "DATA_PATH = DATA_DIR+'/protodune-vd_small.root'\n",
    "\n",
    "cfg = \"\"\"\n",
    "base:\n",
    "  verbosity: info\n",
    "geo:\n",
    "  detector: DETECTOR\n",
    "io:\n",
    "  loader:\n",
    "    batch_size: 4\n",
    "    shuffle: False\n",
    "    num_workers: 4\n",
    "    collate_fn: all\n",
    "    dataset:\n",
    "      name: larcv\n",
    "      file_keys: DATA_PATH\n",
    "      limit_num_files: 10\n",
    "      #entry_list: [6436, 562, 3802, 6175, 15256] # can also be specified as a file\n",
    "      #skip_entry_list: [12, 354] # can also be specified as a file\n",
    "      schema:\n",
    "        input_data:\n",
    "          parser: sparse3d\n",
    "          sparse_event: sparse3d_pcluster\n",
    "        seg_label:\n",
    "          parser: sparse3d\n",
    "          sparse_event: sparse3d_pcluster_semantics\n",
    "        clust_label:\n",
    "          parser: cluster3d\n",
    "          cluster_event: cluster3d_pcluster\n",
    "          particle_event: particle_corrected\n",
    "          sparse_semantics_event: sparse3d_pcluster_semantics\n",
    "          sparse_value_event: sparse3d_pcluster\n",
    "          add_particle_info: true\n",
    "          clean_data: true\n",
    "        ppn_label:\n",
    "          parser: particle_points\n",
    "          particle_event: particle_corrected\n",
    "          sparse_event: sparse3d_pcluster\n",
    "        meta:\n",
    "          parser: meta\n",
    "          sparse_event: sparse3d_pcluster\n",
    "        run_info:\n",
    "          parser: meta\n",
    "          sparse_event: sparse3d_pcluster\n",
    "\"\"\".replace('DETECTOR', DETECTOR).replace('DATA_PATH', DATA_PATH)\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe5105-952f-4d20-a0d4-9762c922e232",
   "metadata": {},
   "source": [
    "`SPINE` expects a ROOT file (created with LArCV, a C++ library to process\n",
    "LArTPC images) as input file. You can explore this file with ROOT alone, if you know\n",
    "how to use ROOT, but the most intuitive way to visualize it is to use the I/O module\n",
    "of `SPINE`.\n",
    "\n",
    "### What are parsers?\n",
    "Images are stored in ROOT + LArCV format. Parsers are classes in `SPINE`\n",
    "that read the information stored in the ROOT file, select just what we are interested\n",
    "in (e.g. particle information ? energy depositions ?) and format it in a friendly way\n",
    "for our chain.\n",
    "\n",
    "They only need to know the names of certain quantities stored in the ROOT file (as TTree,\n",
    "if you know what this is).\n",
    "\n",
    "### Base configuration - a brief gist\n",
    "\n",
    "The base configuration block generally instructs the driver as to how to behave in general\n",
    "(logging, verbosity, etc.). We'll see a lot more of this block later, but for now I will\n",
    "just highlight the verbosity flag, which allows one to set the amount of information reported:\n",
    "- `debug`: Show every logging message coming from SPINE\n",
    "- `info`: Show only basic information messages\n",
    "- `warning`: Only show warnings\n",
    "- `error`: Only show error messages\n",
    "- `fatal`: Only show fatal error messages\n",
    "\n",
    "### I/O Configuration - a brief gist\n",
    "\n",
    "`SPINE` uses the YAML format for its configuration. Here is a skeleton config\n",
    "that shows only the parameters that will matter the most for you:\n",
    "```\n",
    "io:\n",
    "  loader:\n",
    "    batch_size: 16\n",
    "    (...)\n",
    "    sampler: random_sequence\n",
    "    (...)\n",
    "    dataset:\n",
    "      (...)\n",
    "      file_keys: DATA_PATH\n",
    "      (...)\n",
    "      schema:\n",
    "        input_data:\n",
    "          parser: sparse3d\n",
    "          sparse_event: sparse3d_pcluster\n",
    "        (...)\n",
    "```\n",
    "\n",
    "The main things to pay attention to in this data I/O configuration block are:\n",
    "* `batch_size` : number of images loaded per batch\n",
    "* `sampler`: randomization (default: none if sampler is commented out, enabled if you include the RandomSequenceSampler, named random_sequence)\n",
    "* `file_keys`: dataset filename(s). Can be either\n",
    "  * A single file path (supports wildcards)\n",
    "  * A list of file paths (supports wildcards)\n",
    "  * A path to a text file which contains a list of file paths (`\\n` separated)\n",
    "* `schema`: list of data parsers and their individual configurations\n",
    "\n",
    "The schema has a simple format. It has two main components:\n",
    " * `parser`: parser name\n",
    " * `(key, value)` pairs which correspond to arguments of the parser `process` function.\n",
    "\n",
    "```yaml\n",
    "\tmy_custom_data_name:\n",
    "\t  parser: whatever # this is the parser name\n",
    "\t  arg_event: sparse3d_pcluster # this string will be the parser's `arg_event` argument\n",
    "\t  arg_1: false # this string will be the parser's `arg_1` argument\n",
    "\t  # etc\n",
    "```\n",
    "\n",
    "The parser's arguments that end with `_event` are the names of quantities stored in the input ROOT file.\n",
    "\n",
    "A real life example would look like this:\n",
    "\n",
    "```yaml\n",
    "      input_data:\n",
    "        parser: sparse3d\n",
    "        sparse_event: sparse3d_pcluster\n",
    "```\n",
    "\n",
    "This tells us that we want a field called `input_data` (our choice) in the input data\n",
    "dictionary. For the sake of example let's call this input dictionary `data`.\n",
    "The parser name needs to be the first in the list that follows. Hence,\n",
    "`data['input_data']` will be the output of the `sparse3d` parser .\n",
    "That parser will receive as arguments whatever names follow in the list - here, there\n",
    "is just one, `sparse3d_pcluster`.\n",
    "\n",
    "You can have as many such items in the schema list - each of them will be available\n",
    "in the input data dictionary under the name that you specify.\n",
    "\n",
    "Note: some stages of the chain might expect a specific name in the input dictionary.\n",
    "Sometimes this is configurable in the network configuration.\n",
    "\n",
    "These are typical inputs that you would be looking at:\n",
    "* `sparse3d` gets you the actual 3D image, the voxels and various values for each voxel. For each voxel it will parse as many features as you are providing branch names. Here each voxel in `input_data` will have a single feature coming from `sparse3d_pcluster` (the true energy depositions). Each voxel in `seg_label` will have a single feature coming from `sparse3d_pcluster_semantics` (which holds the true semantic labels).\n",
    "* `cluster3d` is parsing particle-wise information and aggregating it. For each non-zero voxel it will provide you with energy deposit, cluster id, interaction id, neutrino vs cosmic label, etc.\n",
    "* `particle_points` retrieves the coordinates and semantic class of points of interest for PPN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934587a-aa74-48e6-a57b-a50d0960bb57",
   "metadata": {},
   "source": [
    "Now that the configuration is defined, you can feed it to `SPINE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from spine.driver import Driver\n",
    "\n",
    "cfg = yaml.safe_load(cfg)\n",
    "\n",
    "# prepare function configures necessary \"handlers\"\n",
    "driver = Driver(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a314d29-f9b4-4714-bfff-5c769f71f2e9",
   "metadata": {},
   "source": [
    "## Iterate\n",
    "One way to iterate through the dataset is to call the `process` function of the driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a68557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.apply_filter(entry_list=[0, 1, 2, 3])\n",
    "data = driver.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c99df-6f35-4833-8af3-07de25ff1c99",
   "metadata": {},
   "source": [
    "You can see that `data` is a dictionary whose keys match the names specified in the configuration block above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ac614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04e012-3c7f-4d46-ad89-b740472d6e5c",
   "metadata": {},
   "source": [
    "As we use a batch loader, each of these objects corresponds to multiple entries in the dataset, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc524c1-37ef-484f-b321-6ab275d9cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa0ba4-766e-4904-8eba-ab9e200f6974",
   "metadata": {},
   "source": [
    "The tensor objects are stored in `TensorBatch` objects which contain functions to quickly slice the tensor between the different entries that make it up. E.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745eca5-983e-42c2-883b-4411d3167de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clust_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d992a-452b-4616-8f28-4d3a8fac5cb8",
   "metadata": {},
   "source": [
    "`clust_label` is made up of 4 entries. Two ways to access it's content:\n",
    "- `data['clust_label'].tensor` returns the full collated tensor of coordinates/values\n",
    "- `data['clust_label'][i]` returns the tensor corresponding to the i^th entry in the batch\n",
    "\n",
    "Let us visualize the distribution of pixel values in the cluster label tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a112c8e-da40-4f3c-9f32-74112896f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import VALUE_COL\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(data['clust_label'].tensor[:, VALUE_COL], range=[0,100], bins=50, histtype='step', linewidth=2)\n",
    "plt.xlabel('Energy [MeV]')\n",
    "plt.ylabel('Space points')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71116138-abb5-4ab7-bda3-f154dbbd1485",
   "metadata": {},
   "source": [
    "Little segway about a nice tool few nice tools:\n",
    "- `%pdef` prints out a function definition\n",
    "- `%pdoc` prints out a docstring (equivalent to python's `help` command)\n",
    "- `%pfile` prints out the entire source code of a specific python module\n",
    "\n",
    "Let's use the last one to check out our globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb22cf9-042f-4e6d-86c4-9c4cad99af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spine.utils.globals\n",
    "\n",
    "%pfile spine.utils.globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347c9f9a-b25c-4303-9620-2f32d741932a",
   "metadata": {},
   "source": [
    "## Taking a look at the images\n",
    "\n",
    "It is time to run this configuration and see what we get out of it! We use Plotly to visualize the 3D images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81165fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255eabad-2ed9-4bfa-bc42-c95bba5a6483",
   "metadata": {},
   "source": [
    "Let's select the second entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f96a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import SHAPE_COL\n",
    "\n",
    "clust_label = data['clust_label'][entry]\n",
    "input_data = data['input_data'][entry]\n",
    "seg_label = data['seg_label'][entry][:, SHAPE_COL]\n",
    "ppn_label = data['ppn_label'][entry]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b4030-aeb2-4fe1-a8d3-bdaa8d10d11f",
   "metadata": {},
   "source": [
    "### Input data\n",
    "Let us visualize the `input_data` first:\n",
    "\n",
    "These are the energy deposits detected by the LArTPC. The energy scale might be true if you are looking at true labels,\n",
    "or it might be a reconstructed energy, depending on what you are loading into `input_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c72d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from spine.vis.geo import GeoDrawer\n",
    "from spine.vis.point import scatter_points\n",
    "from spine.vis.layout import layout3d\n",
    "\n",
    "from spine.utils.globals import GHOST_SHP\n",
    "\n",
    "geo_drawer = GeoDrawer(detector_coords=False)\n",
    "tpc_traces = geo_drawer.tpc_traces(meta=data['meta'][entry])\n",
    "opt_traces = geo_drawer.optical_traces(meta=data['meta'][entry])\n",
    "crt_traces = geo_drawer.crt_traces(meta=data['meta'][entry])\n",
    "\n",
    "nonghost_mask = seg_label < GHOST_SHP\n",
    "\n",
    "trace = []\n",
    "\n",
    "trace += scatter_points(input_data, color=input_data[:, VALUE_COL],\n",
    "                        markersize=2, cmin=0, cmax=50, colorscale='Inferno', name='Input charge')\n",
    "\n",
    "trace += scatter_points(input_data[nonghost_mask],\n",
    "                        color=input_data[nonghost_mask, VALUE_COL],\n",
    "                        markersize=2, cmin=0, cmax=50, colorscale='Inferno', name='Input charge (true non-ghost)')\n",
    "\n",
    "trace += tpc_traces\n",
    "trace += opt_traces\n",
    "trace += crt_traces\n",
    "\n",
    "fig = go.Figure(data=trace, layout=layout3d(use_geo=True, detector_coords=False, meta=data['meta'][entry], show_crt=True))\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc2157-d2a1-4b85-8ab8-ee36b575e5db",
   "metadata": {},
   "source": [
    "What can we do with scatter_points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a8d02-8585-43e4-91da-25429a20e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdoc scatter_points\n",
    "# help(scatter_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da05c50-4e25-4b80-8d46-c359d27f30d6",
   "metadata": {},
   "source": [
    "### Semantic labels\n",
    "Let us look at the semantic labels next: for each voxel, there is a class label which takes integer values in `[0, 4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba6acd-bff7-40e0-bdf6-b1edc6f6e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import PPN_LTYPE_COL\n",
    "from spine.vis.layout import PLOTLY_COLORS\n",
    "\n",
    "trace = []\n",
    "\n",
    "trace+= scatter_points(input_data, color=seg_label,\n",
    "                       markersize=2, cmin=0, cmax=5, colorscale=PLOTLY_COLORS[:6],\n",
    "                       name='Seg. labels (no ghosts)')\n",
    "\n",
    "trace += tpc_traces\n",
    "\n",
    "fig = go.Figure(data=trace,layout=layout3d(meta=data['meta'][entry]))\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ca4d6-de10-4826-a164-69a3ec19e30e",
   "metadata": {},
   "source": [
    "### Points of interest\n",
    "`ppn_label` holds the coordinates of points of interest. They are displayed as big dots in the visualization.\n",
    "The dots color corresponds to the true semantic class attributed to each point of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import PPN_LTYPE_COL\n",
    "from spine.vis.layout import PLOTLY_COLORS\n",
    "\n",
    "trace = []\n",
    "\n",
    "trace+= scatter_points(input_data, color=seg_label,\n",
    "                       markersize=1, cmin=0, cmax=5, colorscale=PLOTLY_COLORS[:6],\n",
    "                       name='Seg. labels (no ghosts)')\n",
    "\n",
    "trace += scatter_points(ppn_label, color=ppn_label[:, PPN_LTYPE_COL],\n",
    "                        markersize=5, cmin=0, cmax=5, colorscale=PLOTLY_COLORS[:6])\n",
    "trace[-1].name = \"True point labels\"\n",
    "\n",
    "trace += tpc_traces\n",
    "\n",
    "fig = go.Figure(data=trace,layout=layout3d(meta=data['meta'][entry]))\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccdc802-030b-4813-bae1-61c71579e60c",
   "metadata": {},
   "source": [
    "### Particle instances\n",
    "A particle instance is a cluster of voxels that belong to an individual particle. Each color here represents\n",
    "a different particle instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import GROUP_COL\n",
    "from spine.vis.layout import HIGH_CONTRAST_COLORS\n",
    "\n",
    "trace = []\n",
    "\n",
    "trace+= scatter_points(clust_label, color=clust_label[:, GROUP_COL],\n",
    "                       markersize=2, cmin=0, cmax=50, colorscale=HIGH_CONTRAST_COLORS,\n",
    "                       name='True group labels')\n",
    "\n",
    "trace += tpc_traces\n",
    "\n",
    "fig = go.Figure(data=trace,layout=layout3d(meta=data['meta'][entry]))\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f2213-281f-4d5e-b16e-e07620ebb3ce",
   "metadata": {},
   "source": [
    "### Interaction groups\n",
    "Particle instances can then be grouped into *interactions*. Each color is a different\n",
    "interaction in this visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import INTER_COL\n",
    "\n",
    "trace = []\n",
    "\n",
    "trace+= scatter_points(clust_label,color=clust_label[:, INTER_COL],\n",
    "                        markersize=2, cmin=0, cmax=50, colorscale=HIGH_CONTRAST_COLORS)\n",
    "trace[-1].name = 'True interaction labels'\n",
    "\n",
    "trace += tpc_traces\n",
    "\n",
    "fig = go.Figure(data=trace,layout=layout3d(meta=data['meta'][entry]))\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0aa57f-51cf-485a-997f-a2db7afa46d6",
   "metadata": {},
   "source": [
    "### Neutrino vs cosmics\n",
    "There are two types of interactions: the ones due to a neutrino traversing the\n",
    "detector volume (i.e. our signal!), and the ones due to cosmic rays (background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.utils.globals import NU_COL\n",
    "\n",
    "trace = []\n",
    "\n",
    "trace += scatter_points(clust_label, color=clust_label[:, NU_COL],\n",
    "                        markersize=2, cmin=-1, cmax=0, colorscale='Portland',\n",
    "                        name='Nu / cosmic labels')\n",
    "\n",
    "trace += tpc_traces\n",
    "\n",
    "fig = go.Figure(data=trace,layout=layout3d(meta=data['meta'][entry]))\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee9bb8-ef7c-4e99-a70e-e8abd140e3e9",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## III. Exercises\n",
    "\n",
    "If you wanna experiment a bit, here's a few suggestions of what to look at:\n",
    "- Using PyROOT, check the number of voxels in a sparse tensor object\n",
    "- Using PyROOT, select the first Particle object in the list, use python `help` to understand its content\n",
    "  - What is the first particle's type? Initial energy? Deposited energy? Does it have children?\n",
    "- Using PyROOT, select the first Neutrino object in the list, use python `help` to understand its content\n",
    "  - What type of neutrino interacted? What was its energy? What was the interaction process?\n",
    "- Check out the remaining available label columns in the `cluster_label` tensor (PID_COL, PGRP_COL, etc.). Do you understand what they represent and do you think they correspond to your expectations?\n",
    "- The parser definitions live under `spine.io.parse.[sparse, cluster, particle, misc]`. Use %pdoc or help to find out what this parser does and the argument it needs, then try to add parsers to the inline configuration and visualize the output, e.g.\n",
    "  - `sparse3d_ghost`\n",
    "  - `particles`\n",
    "  - `meta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434457e1-8e40-447f-8714-b8df1e234894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine.io.torch.dataset import PARSER_DICT # Need to expose this more easily\n",
    "\n",
    "print(PARSER_DICT.keys())\n",
    "help(PARSER_DICT['sparse3d_ghost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74c9a6-2acc-4268-8258-a28613585127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp_container",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
